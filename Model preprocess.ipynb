{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_image_download import simple_image_download as simp\n",
    "\n",
    "# Create an instance of the Downloader class\n",
    "response = simp.Downloader()\n",
    "\n",
    "# Download images using the download method\n",
    "# Note: Join the list of keywords into a single string separated by commas\n",
    "keywords = ''  # If you have multiple keywords, use 'keyword1,keyword2'\n",
    "response.download(keywords=keywords, limit=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def resize_images(directory_path, target_size=([], [])):\n",
    "    for subdir, dirs, files in os.walk(directory_path):\n",
    "        for filename in files:\n",
    "            if any(filename.lower().endswith(ext) for ext in ['.jpeg', '.jpg', '.png', '.bmp']):\n",
    "                file_path = os.path.join(subdir, filename)\n",
    "                img = Image.open(file_path)\n",
    "                img = img.resize(target_size, Image.LANCZOS)\n",
    "                img.save(file_path)\n",
    "                print(f\"Resized image: {file_path}\")\n",
    "\n",
    "# Resize images in the training directory\n",
    "path=''\n",
    "resize_images(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training, move and rename the cloest images to selected folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Settings\n",
    "training_directory = ''\n",
    "new_images_directory = ''\n",
    "save_directory = ''\n",
    "valid_extensions = ['.jpeg', '.jpg', '.png', '.bmp']\n",
    "\n",
    "# Load a pre-trained ResNet50 model trained on ImageNet without the top layer\n",
    "model = ResNet50(include_top=False, weights='imagenet', pooling='avg')\n",
    "\n",
    "def extract_features(img_path, model):\n",
    "    # Load and preprocess the image (assuming already resized to 224x224)\n",
    "    img = image.load_img(img_path)  # No target_size here\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = preprocess_input(img_array)  # Preprocess the image\n",
    "    # Predict the features\n",
    "    features = model.predict(img_array)\n",
    "    return features.flatten()\n",
    "\n",
    "# Function to process a directory of images and extract features\n",
    "def process_images(directory_path, valid_extensions):\n",
    "    features_list = []\n",
    "    file_paths = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if any(filename.lower().endswith(ext) for ext in valid_extensions):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            file_features = extract_features(file_path, model)\n",
    "            features_list.append(file_features)\n",
    "            file_paths.append(file_path)\n",
    "    return features_list, file_paths\n",
    "\n",
    "# Process training and new images\n",
    "training_features, training_paths = process_images(training_directory, valid_extensions)\n",
    "new_features, new_paths = process_images(new_images_directory, valid_extensions)\n",
    "\n",
    "# Train NearestNeighbors\n",
    "if training_features:\n",
    "    features_array = np.array(training_features)\n",
    "    neighbors = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(features_array)\n",
    "else:\n",
    "    raise ValueError(\"No features were extracted from training images.\")\n",
    "\n",
    "# Find closest images\n",
    "if new_features:\n",
    "    new_features_array = np.array(new_features)\n",
    "    distances, indices = neighbors.kneighbors(new_features_array)\n",
    "else:\n",
    "    raise ValueError(\"No features were extracted from new images.\")\n",
    "\n",
    "# Evaluate similarity and copy files\n",
    "distance_threshold = np.percentile(distances, 5) # Assuming the 5th percentile corresponds to top 95% similarity\n",
    "\n",
    "for i, distance in enumerate(distances.flatten()):\n",
    "    if distance <= distance_threshold:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S%f\")\n",
    "        new_basename = f\"{timestamp}.jpg\"\n",
    "        new_name_path = os.path.join(new_images_directory, new_basename)\n",
    "\n",
    "        # Rename and copy the image\n",
    "        os.rename(new_paths[i], new_name_path)\n",
    "        shutil.copy(new_name_path, os.path.join(save_directory, new_basename))\n",
    "        print(f\"Renamed and copied {new_name_path}\")\n",
    "    else:\n",
    "        print(f\"Image {new_paths[i]} is not similar enough to be renamed.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
